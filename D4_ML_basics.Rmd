---
title: "기계학습의 기초와 통계적 모델링"   
author: "Yoon-Ho Hong" 
date: "2022-08-23"
output: 
  html_document:
    toc: yes
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

이번 시간에는 기계학습의 기초가 되는 다음 개념을 다룹니다.

-   추정, 예측과 추론
-   모수 vs. 비모수
-   유연성과 정확성의 관계
-   편향과 분산의 관계

## 기계학습

기계학습은 지도 기계학습과 비지도 기계학습으로 구분됩니다.    

지도 기계학습은 입력 변수를 기반으로 출력 변수를 예측하는 모델을 만드는 것이고, 비지도 기계학습은 출력 변수 없이 입력 변수만 가지고 자료의 상관 관계와 구조를 파악하는 것입니다.    

출력 변수는 일반적으로 반응 변수 혹은 응답 변수, 종속 변수, 결과 변수라고 불리며 보통 $Y$를 사용하여 나타냅니다.  

입력 변수는 보통 $X$로 나타내고, 아래 첨자를 사용하여 서로 다른 입력 변수들을 구분한다. 입력 변수는 설명 변수, 예측 변수, 독립 변수, 특징(features) 또는 그냥 변수라고도 불립니다.  

$X$와 $Y$의 관계를 다음 식으로 나타낼 수 있습니다. 지도 기계학습은 결국 f를 추정하는(estimate) 것으로 볼 수 있습니다.    

$$Y = f(X) + e$$

$X$ ($X_1$ + $X_2$ + ... + $X_p$): features  
$Y$; response variable  
$e$; random error term (independent of $X$, mean = 0) 

위 식에서 $e$은 오차항으로 $X$와 무관하고, 평균은 0입니다.    

## $f$를 추정하는 이유

f를 어떻게 추정하는지 하는 방법을 구체적으로 살펴보기에 앞서, 우선 f를 추정하고자 하는 목적, 이유에 대해 살펴봅시다.  

크게 두가지로 구분해 볼 수 있는데, 바로 예측과 추론입니다.  

### 예측

예측 문제에서 $\hat{f}$은 보통 블랙박스로 취급됩니다.   $\hat{f}$이 정확한 예측을 제공한다면 그것의 내용에 대해서는 통상 관심이 없기 때문입니다.  

$$\hat{Y} = \hat{f}(X)$$

$\hat{Y}$은 Y에 대한 예측(prediction) 결과를 나타내며, $\hat{f}$은 f에 대한 추정을 나타냅니다.  

$\hat{Y}$의 정확성은 오차를 얼마나 줄일 수 있느냐에 달려있습니다.  

오차는 크게 축소가능한 오차(reducible error)와 축소불가능한 오차(irreducible error)로 구분할 수 있습니다.  

축소가능 오차(reducible error): 가장 적절한 기계학습 기법을 사용하여 f를 추정함으로써 $\hat{f}$의 정확성을 개선할 수 있다.  

축소불가능 오차(irreducible error): 근본적으로 측정할 수 없는 변동성이나, 혹은 측정되지 않은 어떤 유용한 변수들에 기인하는 오차를 말합니다.  

축소불가능 오차는 예측 정확도의 상한선이 되겠지만, 그 경계는 현실적으로 거의 언제나 알려져 있지 않습니다.    

### 추론

추론(inference)은 X가 변함에 따라 Y가 어떻게 영향을 받는지를 이해하는데 관심이 있습니다. 따라서, $\hat{f}$은 블랙박스로 취급될 수 없습니다. 그것의 정확한 형태를 알아야 할 필요가 있기 때문입니다.  
   
다음과 같은 질문은 추론과 관련이 있습니다.     

- 어떤 예측 변수들이 결과 변수 값과 연관되어 있는가?
- 예측 변수와 결과 변수간에는 어떤 연관성이 있는가?
- 예측 변수와 결과 변수간의 연관성은 선형 관계인가 아니면 더 복잡한 관계인가?

## f를 추정하는 방법

훈련 데이터를 이용하여 f를 추정하는데, 이를 위한 기계학습 기법들은 크게 모수적 방법과 비모수적 방법으로 나누어 볼 수 있습니다.     

### 모수적 방법

모수적 방법(parametric)은 먼저 f 함수의 형태에 대한 가정으로부터 출발합니다.    

예를 들면, 아주 단순하게 Y는 X에 대해 선형 관계라고 가정할 수 있습니다.     

$$f(X) = \beta_0 + \beta_1X_1 + \beta_2X_2 + ...+\beta_pX_p$$

다음으로 훈련데이터를 이용하여 모델을 적합(fit)하는 절차가 필요합니다.     

이것은 위 선형 모델의 경우, 파라미터 집합 $\beta_0$, $\beta_1$, $\beta_2$,..., $\beta_p$을 추정하는 절차이며, 선형 모델의 적합에 가장 일반적으로 사용되는 기법은 최소제곱법(least squares)입니다.     

**figure**   
<img src="img/least_flexible_model.png" style="border: #A9A9A9 1px solid; width:75%"/>

<img src="img/flexible_model.png" style="border: #A9A9A9 1px solid; width: 75%"/>

<img src="img/very_flexible_model.png" style="border: #A9A9A9 1px solid; width: 75%"/>

### 비모수적 방법(non-parametric)

비모수적 방법은 함수 $f$의 형태에 대해 어떤 가정도 하지 않고, 가능한 학습 데이터에 가깝게 그러나 과적합(overfitting)을 피하면서 함수 $f$를 추정하는 것입니다.  

## 모델의 유연성과 해석 가능성(Model flexibility & Interpretability)

아래 그림은 모델의 유연성과 해석력의 관계에 대한 것입니다.   

**figure** 
<img src="img/flexibility_interpretability.png" style="border: #A9A9A9 1px solid; width: 75%"/>

우리가 추론에는 관심이 없고, 예측에만 관심이 있다면 가장 유연한 모델을 사용하는 것이 해석력을 희생하더라도 정확성을 높일 수있는 최선의 선택이라고 예상할 수 있습니다.  

그러나, 놀랍게도 덜 유연한 방법을 사용할 때 더 정확한 예측을 얻을 수 있는 사례들을 종종 볼 수 있습니다.      

직관에 반하는 것처럼 보이는 이러한 현상을 어떻게 설명할 수 있을까요? 이것은 아주 유연한 방법들이 지닌 잠재적인 과적합(overfitting)의 문제와 관련이 깊습니다.  

이것에 대한 상세한 설명에 앞서 모델의 정확도 평가에 대해 먼저 살펴봅시다.   

## 모델의 정확도 평가 (How to asess the accuracy of model?)

기계 학습 모델의 정확도를 어떻게 평가할까요? 회귀와 분류로 나누어 살펴봅시다.      

### 회귀 (Regression)

기계학습 모델의 성능을 평가한다는 것은 예측치와 관측치가 얼마나 일치하는지 측정한다는 것입니다.     

회귀 문제에서 가장 일반적으로 사용되는 척도는 아래 식으로 주어지는 평균제곱오차(mean squared error), 혹은 제곱근을 씌운 root mean squared error 입니다.  

Mean Squared Error (MSE)  

$$MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{f}(x_i))^2$$

학습 데이터(training data)를 이용하여 계산한 MSE는 training MSE 라고 한다.   

우리는 일반적으로 기계학습 모델이 training data에서 얼마나 잘 작동하는지에는 관심이 없습니다.     

중요한 것은 검정 데이터(test data)에 적용할 때 얻는 예측 정확도입니다 (test MSE).  

### 분류 (Classification)

분류 문제에서 분류기 $\hat{f}$의 정확도를 수량화하는 가장 흔한 지표는 아래 식으로 주어지는 오차율(error rate)입니다.  

오차율(Error rate)      

$$\frac{1}{n}\sum_{i=1}^{n}I(y_i \neq \hat{y_i})$$

$\hat{y_i}$는 $\hat{f}$를 사용하여 예측된 i번째 관측치에 대한 클래스 표시(label)이고,  
$I(y_i \neq \hat{y_i})$는 indicator variable로 $y_i \neq \hat{y_i}$이면 1이고, $y_i = \hat{y_i}$이면 0이다.  

## 편향 분산 절충(Bias-Variance trade-off)

편향(Bias)은 추정치가 실제값에서 얼마나 벗어나 있는지를 가리키는 개념입니다.  

반면, 분산은 학습 데이터(training data)에 따라 추정치가 얼마나 변화하는지를 나타내는 개념입니다.  

일반적으로 더 유연한 모델을 사용할 때 편향은 줄어드나, 분산은 증가합니다.  

즉, 모델의 유연성을 증가시킴에 따라 편향의 감소가 검정 데이터에서의 오차를 줄이지만, 어느 지점을 넘어서면 편향의 감소분에 비해 분산의 증가분이 더 커져 검정 데이터에서의 오차는 오히려 증가하게 됩니다. 이를 과적합(overfitting)이라고 합니다.  

따라서, 최적의 모델을 만드는 것은 결국 분산과 편향의 절충 문제로 볼 수 있습니다.  

*figure* <img src="img/bias_variance_tradeoff.png" style="border: #A9A9A9 1px solid; width:75%"/>  

<img src="img/knn_bias_variance_tradeoff.png" style="border: #A9A9A9 1px solid; width:75%"/>  

*공짜 점심은 없다(No free lunch theorem)*    

기계학습 모델의 성능, 즉 정확도 평가에서, 모든 자료에 대해 가장 좋은 결과를 줄 수 있는 단 하나의 방법(master algorithm)은 없을까 생각해봅시다.     

결론부터 말하자면, 그러한 기법은 없다는 것이 현재의 정설입니다. 실은 이것이 우리가 앞으로 여러가지 기계학습 기법을 살펴보아야 하는 이유이기도 합니다. 

## 통계적 모델링

통계적 모델링이란 확률적인 모형을 가지고 현실세계의 데이터 생성과정을 모방하는 것을 가리킵니다.  

> All models are wrong. Some models are useful.   
-- George Box

통계적 모델링의 목적은 다음과 같습니다.  

1.  불확실성의 측정
2.  추론
3.  가설 검정
4.  예측

앞서 추론과 예측에 대해서는 간단히 살펴보았고, 가설 검정에 대해서는 일반 통계 수업에서 자주 다루었으니, 이번에는 불확실성의 추정에 대해서 조금 더 자세히 살펴봅시다.   

가장 간단한 예로 평균을 구하는 문제를 생각해봅시다.    

우리는 *표본*의 정보를 사용하여 *모집단*의 평균을 추정하고자 합니다. 예를 들어, 어떤 변수 Y의 *모평균* $\mu$를 알고자 한다고 해봅시다.  

유감스럽게도 $\mu$는 알려져 있지 않습니다. 그러나, 우리는 Y의 n개 관측치, $y_1$, $y_2$, ..., $y_n$를 알수 있고, 표본 평균을 알 수 있습니다.  

$$\mu = mean(\bar{X})$$ 그럼, 표본평균은 모평균의 추정값으로 얼마나 정확하다고 말할 수 있을까요?  

우리는 모평균을 모르기 때문에 사실 표본 평균이 모평균의 추정치로서 얼마나 정확한지 알수 없습니다. 따라서, 표본평균이 모평균의 추정값으로 얼마나 정확한가에 대한 질문은 표본 평균의 변동성을 묻는 질문입니다.  

표본 평균의 변동성을 나타내는 지표가 바로 표준 오차입니다.  

표준오차는 *표본평균*의 표준 편차를 말합니다. 표본 평균의 평균은 모평균과 같으므로, 표준오차는 표본평균이 모평균으로부터 얼마나 떨어져 있는가를 나타냅니다.  

표준오차(SEM, standard error of mean)는아래 식과 같이 모집단의 표준편차(sigma)를 표본 크기(n)의 제곱근으로 나누어서 구할수 있습니다.  

$$SEM = \frac{\sigma}{\sqrt{n}}$$ $\sigma$: 모표준 편차  
$n$: 관측치의 개수(표본의 크기)  

위 식에서 알 수 있듯이 표준 오차는 모집단의 표준 편차가 작을수록, 표본의 크기가 클수록 작아진다는 것을 직관적으로 알수 있습니다.  

우리는 모집단의 표준편차를 알 수 없지만, 표본 표준편차의 기대값이 모표준편차와 같다는 것을 알고 있습니다(수학적 증명은 생략하겠습니다).   

모표준편차의 불편 추정량(unbiased estimate)으로서의 표본 표준편차는 아래와 같은 식으로 구합니다.  

$$s = \sqrt\frac{\sum(X_i-\bar{X})^2}{n-1}$$ 왜, n 대신 n-1을 사용하는 걸까요?    
위 식과 같이 n-1을 사용해서 구한 표준편차는 모집단의 표준편차에 대한 불편 추정량으로서의 표본 표준편차입니다.  

모집단의 표준편차는 항상 표본의 표준편차보다 클 것입니다. 1을 빼주는 것은 우리는 표본의 평균을 알고 있고, 표본의 평균이 주어지면 잔차의 합은 항상 0이기 때문입니다.  

즉, 모집단의 분산에 대한 불편 추정량으로서의 표본 분산에 대한 자유도는 n이 아니라 n-1 이 됩니다.  

## 부트스트래핑

부트스트래핑이란(bootstrapping) 모수를 추정하거나 가설 검정을 위해서 무작위로 표본을 추출하는 과정을 가리킵니다. 이 때 중복을 허용합니다.       

그럼, 앞서 모평균을 추정하고 표본 평균의 변동성을 측정하는 문제에 적용해보기로 합시다.  

우선, 다음과 같은 모집단이 있다고 해봅시다.  

```{r}
set.seed(1)
pop = rnorm(1000, 0, 10) # number=1000, mean=0, sd=10
mean(pop)
sd(pop)
```

모집단에서 표본을 추출합니다.  

```{r}
sampl = sample(pop, 100, replace = F) 
```

부트스트래핑을 하기전에 우선 표본 평균(모평균의 추정치로서의)과 표준 오차, 95% 신뢰구간을 구해봅시다.  

```{r}
x_bar = mean(sampl) # 표본 평균 
n = length(sampl) # 표본 크기 
s = sqrt(var(sampl)*n/(n-1)) # 모표준편차의 불편추정량으로서 표본 표준편차 
sem = s/sqrt(n)
CI = c(x_bar - 2*sem, x_bar + 2*sem)
x_bar; sem; CI
```

이제 부트스트래핑을 적용해 모평균의 추정치와 표준 오차, 95% 신뢰구간을 구해봅시다.  

먼저 다음과 같은 함수를 정의해줍니다.  

```{r}
fn = function(z, index){
  mean(z[index])
} # function need two arguments, the second one should be index
```

이제 표본에서 하위 표본을 추출하고(복원을 허락), 해당 하위 표본의 평균을 구하는 함수를 적용합니다.  

```{r}
ind = sample(length(sampl), length(sampl), replace = T)
fn(sampl, ind)
```

위 과정을 n번 반복합니다.  

```{r}
# boot 
library(boot)
res = boot(sampl, fn, R=1000) 
res$t0 
# original = the mean of the original sample
mu = mean(res$t)
sem = sd(res$t) # standard deviation of the sample mean 
ci = boot.ci(res, type = "norm")
mu; sem; ci
```

위에서 구한 표준오차, 신뢰구간과 비교해봅니다.     

## 사고 실험

> 의학,의료 분야에서 간단한 예측 문제와 복잡한 문제의 예를 들어봅시다. 각각의 경우 어떤 기계학습 모델을 사용하는 것이 적절할지 생각해봅시다.

간단한 예측 작업은 적은 수의 예측 변수를 가지고 높은 정확도로 수행될 수 있는 작업으로 정의됩니다.
예를 들어, 고칼륨혈증의 발생을 예측하는 것은 신장 기능, 칼륨 보충제 사용 및 특정 약물의 복용과 같은 작은 변수 세트에서 가능할 수 있습니다. 반면, 복잡한 예측 작업은 적은 수의 예측 변수로 정확하게 예측할 수 없는 작업으로 정의됩니다. 예를 들어, 병리 슬라이드에서 이상을 식별하려면 수백만 픽셀에서 분명하지 않은 패턴을 평가해야합니다.

일반적으로 간단한 예측 작업은 기존 모델(예를 들면, 로지스틱 회귀와 같은)을 사용하여 수행할 수 있으며 복잡한 작업에는 더 복잡한 모델 (예를 들면, 딥러닝과 같은)이 필요합니다.

> 당신이 훌륭한 예측 모델을 개발했다고 가정합니다. 해당 예측 모델이 실제로 어떻게 사용될지를 생각해봅시다.

예측 작업을 단순하거나 복잡한 것으로 분류하는 것 외에도 모델이 실제로 어떻게 사용될지를 고려해야합니다.

모델이 bedside scoring system (예를 들어, 폐색전증의 가능성을 평가하는 Wells score)에 사용될 경우, 인간에 의해 선별된 적은 수의 변수를 사용하는 것이 바람직합니다. 이 경우 해당 예측 모델은 더 복잡한 모델만큼 효과적일 수 있습니다.

모델이 사람의 개입없이 원시 데이터 자체를 자동으로 분석해야하는 경우 작업이 더 복잡해지고 복잡한 모델이 일반적으로 더 유용해집니다. 이 경우, 원시 데이터를 더 작은 정제된 데이터 세트로 처리하는 규칙 세트를 작성할 수 있으며, 이는 예측 작업이 단순 할 경우 기존 모델에 적합할 수 있습니다. 그러나 이러한 규칙을 작성하고 업데이트하는 데 많은 시간이 소요됩니다.

> 기계학습 모델 구축을 위해 얼마나 많은 훈련 데이터가 있어야 할지 생각해봅시다.

간단한 예측 작업은 일반적으로 모델을 구축하기 위해 많은 예제를 배울 필요가 없습니다. 복잡한 모델의 훈련에는 일반적으로 더 많은 예가 필요합니다. 미리 정해진 수의 예는 없지만 복잡한 모델을 구성하려면 최소한 수천 개의 예가 필요하며 예측 작업이 복잡할수록 더 많은 데이터가 필요합니다. 정확한 모델을 구성하는데 필요한 훈련 예제의 수를 줄이기 위해 특수한 방법을(e.g., transfer learning) 사용하기도 합니다.

> 예측 모델이 얼마나 해석 가능해야하는지 생각해봅시다.

단순 예측모델은 평가된 변수의 수가 매우 적기 때문에 해석이 용이할 수 있습니다.

반면에 복잡한 모델은 복잡한 패턴을 식별하는 법을 학습하는 것이기 때문에 본질적으로 해석하기가 어렵습니다. 이러한 복잡성으로 인해 보다 정확한 예측이 가능하지만 특정 예측의 미묘한 패턴을 간결하게 제시하거나 설명하기가 어렵다는 단점이 있습니다.

> 아래 (a)에서 (c)까지의 각 항목에 대해, 유연한 기계학습 방법의 성능이 유연성이 없는 방법보다 더 우수하거나 혹은 더 나쁠 것으로 예상하는지 여부를 표시하십시오. 왜 그렇게 생각하는지 설명하십시오.

(a) 표본 크기 n은 매우 크며 예측 변수 p의 수는 적다.
(b) 예측 변수 p의 수는 매우 많고, 관측 수 n은 적다.
(c) 예측 자와 반응 사이의 관계가 매우 비선형적이다.
